{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDING_BOX_KEYS = ['Width', 'Height', 'Left', 'Top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_sample_from_list(l):\n",
    "    n = len(l)\n",
    "    index = np.random.randint(n)\n",
    "    return l[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_to_bytes(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        source_bytes = f.read()\n",
    "    return source_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(img, bounding_box, text='', block_type = ''):\n",
    "    block_type_colors = {\n",
    "        'WORD': (255, 0, 0), \n",
    "        'LINE': (0, 255, 0), \n",
    "        'CELL': (0, 0, 255), \n",
    "        'TABLE': (255, 255, 0), \n",
    "        'PAGE': (255, 0, 255),\n",
    "        'SELECTION_ELEMENT': (150, 150, 150),\n",
    "    }\n",
    "    color = block_type_colors[block_type] if block_type in block_type_colors.keys() else (0, 255, 255)\n",
    "\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    w, h = int(bounding_box[0]*width), int(bounding_box[1]*height)\n",
    "    x, y = int(bounding_box[2]*width), int(bounding_box[3]*height)\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), color, 3)\n",
    "    cv2.putText(img, text, (x, y+20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 255), 2, cv2.LINE_AA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image, title=''):\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    plt.title(title)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_bounding_boxes(file_path, bounding_boxes, block_types=None, text=None, text_size=None):\n",
    "    if block_types is None:\n",
    "        block_types = ['' for i in range(len(bounding_boxes))]\n",
    "    if text is None:\n",
    "        text = ['' for i in range(len(bounding_boxes))]\n",
    "\n",
    "    img_bounding_boxes = cv2.imread(file_path)\n",
    "    for index, bounding_box in enumerate(bounding_boxes):\n",
    "        draw_bounding_box(\n",
    "            img_bounding_boxes,\n",
    "            bounding_box,\n",
    "            text=text[index],\n",
    "            block_type=block_types[index],\n",
    "        )\n",
    "    plot_image(img_bounding_boxes, title=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Textract - Analyze document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relationship_type_ids(ids, relationships):\n",
    "    relationships_type = []\n",
    "    relationships_ids = []\n",
    "    for relationship in relationships:\n",
    "        try:\n",
    "            relationship = relationship[0]\n",
    "            relationships_type.append(relationship['Type'])\n",
    "            relationships_ids.append(\n",
    "                [ids[ids == id_].index[0] for id_ in relationship['Ids']]\n",
    "            )            \n",
    "        except:\n",
    "            relationships_type.append(None)\n",
    "            relationships_ids.append(None)\n",
    "    return relationships_type, relationships_ids\n",
    "\n",
    "def get_father_ids(children_ids):\n",
    "    father_id = [[] for index in range(len(children_ids))]\n",
    "    for index, relationship_ids in enumerate(children_ids):\n",
    "        if isinstance(relationship_ids, list):\n",
    "            [father_id[id_].append(index) for id_ in relationship_ids]\n",
    "    return father_id\n",
    "\n",
    "def get_analyze_document(analyze_document, plot=False):\n",
    "\n",
    "    # Data cleaning\n",
    "    analyze_document['Relationship_type'], analyze_document['Relationship_ids'] = get_relationship_type_ids(\n",
    "        analyze_document['Id'], analyze_document['Relationships']\n",
    "    )\n",
    "    analyze_document.drop('Relationships', axis=1, inplace=True)\n",
    "\n",
    "    analyze_document['Father_id'] = get_father_ids(analyze_document['Relationship_ids'])\n",
    "\n",
    "    analyze_document['Bounding_box'] = analyze_document['Geometry'].map(lambda x: tuple(x['BoundingBox'].values()))\n",
    "    analyze_document.drop('Geometry', axis=1, inplace=True)\n",
    "\n",
    "    analyze_document['Text'] = analyze_document['Text'].fillna('')\n",
    "\n",
    "    # Plot image and bounding boxes\n",
    "    if plot:\n",
    "        plot_image_bounding_boxes(file_path, analyze_document['Bounding_box'], list(analyze_document['BlockType']))\n",
    "\n",
    "    return analyze_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blocktypes_indexes(blocktype_serie, blocktypes):\n",
    "        return [index for index, block in enumerate(blocktype_serie) if block in blocktypes]\n",
    "\n",
    "def get_blocktype_bounding_boxes(analyze_document, blocktypes):\n",
    "    blocktype_indexes = get_blocktypes_indexes(analyze_document['BlockType'], blocktypes)\n",
    "    bounding_boxes = analyze_document.iloc[blocktype_indexes]\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_values(analyze_document, file_path, plot=False):\n",
    "    table_cells = analyze_document[\n",
    "        ['BlockType', 'Text', 'RowIndex', 'ColumnIndex', 'Relationship_ids', 'Father_id', 'Bounding_box']\n",
    "    ]\n",
    "    table_cells = table_cells[table_cells['BlockType'] == 'CELL']\n",
    "    table_cells['Father_id'] = table_cells['Father_id'].map(lambda x: x[0])\n",
    "\n",
    "    cell_text = []\n",
    "    for cell_children in table_cells['Relationship_ids']:\n",
    "        cell_text.append(\n",
    "            ' '.join(list(analyze_document['Text'].iloc[cell_children].values)) \n",
    "            if cell_children is not None else None\n",
    "        )\n",
    "    table_cells['Text'] = cell_text\n",
    "    table_cells['Text'].fillna('', inplace=True)\n",
    "\n",
    "    if(plot):\n",
    "        plot_image_bounding_boxes(file_path, list(table_cells['Bounding_box']), text=list(table_cells['Text']))\n",
    "\n",
    "    df_table = []\n",
    "    for table_father in table_cells['Father_id'].unique():\n",
    "        table_text = table_cells[table_cells['Father_id'] == table_father]\n",
    "        for index, row in enumerate(table_text['RowIndex'].unique()):\n",
    "            df_table.append(\n",
    "                [table_father] + list(table_text[table_text['RowIndex'] == row]['Text'].values)\n",
    "            )\n",
    "    df_table = pd.DataFrame(df_table)\n",
    "\n",
    "    null_columns = df_table.isnull().sum()\n",
    "    null_columns = null_columns[null_columns == len(df_table)].index\n",
    "    df_table.drop(null_columns, axis=1, inplace=True)\n",
    "\n",
    "    return df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_point_inside_box(point, box):\n",
    "    if box[2] <= point[0] and point[0] <= box[2] + box[0]:\n",
    "        if box[3] <= point[1] and point[1] <= box[3] + box[1]:\n",
    "            return True \n",
    "    return False\n",
    "\n",
    "def is_box_inside_box(small_box, big_box):\n",
    "    points = [\n",
    "        (small_box[2], small_box[3]), \n",
    "        (small_box[2] + small_box[0], small_box[3]), \n",
    "        (small_box[2]               , small_box[3] + small_box[1]), \n",
    "        (small_box[2] + small_box[0], small_box[3] + small_box[1])\n",
    "    ]\n",
    "    for point in points:\n",
    "        if not is_point_inside_box(point, big_box):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_box_partially_inside_box(small_box, big_box):\n",
    "    points = [\n",
    "        (small_box[2], small_box[3]), \n",
    "        (small_box[2] + small_box[0], small_box[3]), \n",
    "        (small_box[2]               , small_box[3] + small_box[1]), \n",
    "        (small_box[2] + small_box[0], small_box[3] + small_box[1])\n",
    "    ]\n",
    "    for point in points:\n",
    "        if is_point_inside_box(point, big_box):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def are_boxes_inside_box(boxes, big_box):\n",
    "    return [is_box_inside_box(box, big_box) for box in boxes]\n",
    "\n",
    "def are_boxes_complete_or_partially_inside_box(boxes, big_box):\n",
    "    return [is_box_inside_box(box, big_box) or is_box_partially_inside_box(box, big_box) for box in boxes]\n",
    "\n",
    "def is_box_inside_any_box(box, boxes):\n",
    "    for box_ in boxes:\n",
    "        if box == box_:\n",
    "            continue\n",
    "        if is_box_inside_box(box, box_):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(analyze_document, file_path, plot=False):\n",
    "    table_bounding_boxes = get_blocktype_bounding_boxes(analyze_document, ['TABLE'])\n",
    "    line_word_bounding_boxes = get_blocktype_bounding_boxes(analyze_document, ['LINE', 'WORD'])\n",
    "\n",
    "    if len(table_bounding_boxes) > 0:\n",
    "        # Select line and word block type rows that do not belong to a table\n",
    "        paragraph_content = []\n",
    "        for table_bounding_box in table_bounding_boxes['Bounding_box']:\n",
    "            paragraph_content.append(\n",
    "                are_boxes_inside_box(\n",
    "                    line_word_bounding_boxes['Bounding_box'].values, table_bounding_box\n",
    "                )\n",
    "            )\n",
    "        selected_paragraphs = paragraph_content[0]\n",
    "        for paragraph in paragraph_content[1:]:\n",
    "            selected_paragraphs = [selected_paragraphs[idx] or paragraph[idx] for idx in range(len(selected_paragraphs))]\n",
    "        selected_paragraphs = [not a for a in selected_paragraphs]\n",
    "        text_indexes = line_word_bounding_boxes.iloc[selected_paragraphs].index\n",
    "    else:\n",
    "        text_indexes = line_word_bounding_boxes.index\n",
    "\n",
    "    # Remove duplicate bounding boxes\n",
    "    paragraph_content = analyze_document.iloc[text_indexes]\n",
    "    paragraph_content = analyze_document.iloc[paragraph_content.Father_id.map(lambda x: x[0] in paragraph_content.index).index]\n",
    "    paragraph_content = paragraph_content[['Text', 'Bounding_box']]\n",
    "    paragraph_content = paragraph_content.iloc[\n",
    "        [not(is_box_inside_any_box(bounding_box, paragraph_content['Bounding_box'])) for bounding_box in paragraph_content['Bounding_box']]\n",
    "    ]\n",
    "    paragraph_content.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if plot:\n",
    "        plot_image_bounding_boxes(file_path, paragraph_content['Bounding_box'])\n",
    "\n",
    "    # Get lines\n",
    "    lines_idx = []\n",
    "    if len(paragraph_content) > 0:\n",
    "        line = [paragraph_content['Bounding_box'][0]]\n",
    "        line_idx = [0]\n",
    "        x_coordinate = line[0][3]\n",
    "        tolerance = line[0][1] / 2.0\n",
    "        for index, bounding_box in enumerate(paragraph_content['Bounding_box'][1:]):\n",
    "            if np.abs(x_coordinate - bounding_box[3]) < tolerance:\n",
    "                line.append(bounding_box)\n",
    "                line_idx.append(index+1)\n",
    "            else:\n",
    "                lines_idx.append(line_idx)\n",
    "                line = [bounding_box]\n",
    "                line_idx = [index+1]\n",
    "                x_coordinate = line[0][3]\n",
    "                tolerance = line[0][1] / 2.0\n",
    "        lines_idx.append(line_idx)\n",
    "    lines_text = []\n",
    "    for line_idx in lines_idx:\n",
    "        lines_text.append([paragraph_content['Text'][idx] for idx in line_idx])\n",
    "    lines_text = pd.DataFrame(lines_text)\n",
    "    \n",
    "    return lines_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aws_analyze_document(file_path, plot=False):\n",
    "    # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/textract.html#Textract.Client.analyze_document\n",
    "    # AWS Textract request\n",
    "    client_textract = boto3.client('textract')\n",
    "    analyze_document_original = pd.DataFrame(\n",
    "        client_textract.analyze_document(\n",
    "            Document={'Bytes': convert_img_to_bytes(file_path)},\n",
    "            FeatureTypes=['TABLES'],\n",
    "        )['Blocks']\n",
    "    )\n",
    "    analyze_document = get_analyze_document(analyze_document_original, plot=plot)\n",
    "    return analyze_document   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(file_path, plot=False):\n",
    "    return\n",
    "    # AWS Textract has its own way to preprocess images\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.bitwise_not(gray_image)\n",
    "    ret, binary_image = cv2.threshold(gray_image, 32, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    image = binary_image.copy()\n",
    "    Image.fromarray(image).save(file_path)\n",
    "\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(15, 15))\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS connection    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aws_analyze_document(file_path):\n",
    "    if file_path.split('.')[-1] == 'pdf':\n",
    "        pdf_pages = convert_from_path(file_path, dpi=200)\n",
    "        file_paths = []\n",
    "        for index, pdf_page in enumerate(pdf_pages):\n",
    "            file_paths.append(file_path[:-4] + '_p%d.jpg' % index)\n",
    "            pdf_page.save(file_paths[-1], 'JPEG')\n",
    "            image_preprocessing(file_paths[-1], plot=False)\n",
    "        df_tables = []\n",
    "        df_text = []\n",
    "        for file_path in file_paths:\n",
    "            analyze_document = aws_analyze_document(file_path)\n",
    "            df_tables.append(get_table_values(analyze_document, file_path, plot=False))\n",
    "            df_text.append(get_text(analyze_document, file_path, plot=False))        \n",
    "    else:\n",
    "        image_preprocessing(file_path, plot=False)\n",
    "        analyze_document = aws_analyze_document(file_path)\n",
    "        df_tables = get_table_values(analyze_document, plot=False)\n",
    "        df_text = get_text(analyze_document, plot=False)\n",
    "    return (df_tables, df_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'text0detection'\n",
    "bucket_files = boto3.client('s3').list_objects(Bucket=bucket)['Contents']\n",
    "bucket_files = [x['Key'] for x in bucket_files][1:]\n",
    "\n",
    "bucket_file = 'Doc3.pdf'\n",
    "file_path = os.path.join('images', bucket_file)\n",
    "if bucket_file not in os.listdir('images'):\n",
    "    boto3.client('s3').download_file(\n",
    "        bucket, \n",
    "        file_path, \n",
    "        file_path\n",
    "    )\n",
    "df_tables, df_text = get_aws_analyze_document(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc1.pdf\n",
      "images/Doc1.pdf  - Time:  15.924110889434814\n",
      "Doc2.pdf\n",
      "images/Doc2.pdf  - Time:  19.13053870201111\n",
      "Doc3.pdf\n",
      "images/Doc3.pdf  - Time:  27.493390321731567\n",
      "Total time:  62.54954695701599\n",
      "Mean time:  20.84934663772583\n"
     ]
    }
   ],
   "source": [
    "bucket = 'text0detection'\n",
    "bucket_files = boto3.client('s3').list_objects(Bucket=bucket)['Contents']\n",
    "bucket_files = [x['Key'] for x in bucket_files][1:]\n",
    "bucket_files = ['Doc1.pdf', 'Doc2.pdf', 'Doc3.pdf']\n",
    "\n",
    "file_tables = []\n",
    "file_text = []\n",
    "times = []\n",
    "start_time = time.time()\n",
    "for bucket_file in bucket_files:\n",
    "    begin_time = time.time()\n",
    "    print(bucket_file)\n",
    "    file_path = os.path.join('images', bucket_file)\n",
    "    if bucket_file not in os.listdir('images'):\n",
    "        boto3.client('s3').download_file(\n",
    "            bucket, \n",
    "            file_path, \n",
    "            file_path\n",
    "        )\n",
    "    df_tables, df_text = get_aws_analyze_document(file_path)\n",
    "    file_tables.append(df_tables)\n",
    "    file_text.append(df_text)\n",
    "    times.append(time.time() - begin_time)\n",
    "    print(file_path, ' - Time: ', times[-1])\n",
    "print('Total time: ', time.time() - start_time)\n",
    "print('Mean time: ', np.mean(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science",
   "language": "python",
   "name": "ciencia_datos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
